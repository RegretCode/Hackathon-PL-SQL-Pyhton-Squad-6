"""
Fun√ß√µes utilit√°    output.append("üß™ TRADU√á√ÉO #{result['translation_id']}")
    output.append("=" * 80)
    
    output.append(f"\nüìù SQL Original:")
    output.append(f"   {result['original_sql']}")
    
    output.append(f"\nüî• Spark SQL:")
    output.append(f"   {result['spark_sql']}")
    
    if result['translation_available']:
        output.append(f"\nüêç API PySpark DataFrame:")
        pyspark_lines = result['pyspark_code'].split('\n')
        for line in pyspark_lines:
            if line.strip():
                output.append(f"   {line}")
    else:
        output.append(f"\n‚ùå API PySpark DataFrame: N√£o dispon√≠vel (consulta complexa)")
    
    status = 'Sucesso' if result['translation_available'] else 'Parcial (apenas Spark SQL)'
    output.append(f"\n‚úÖ Status da Tradu√ß√£o: {status}") formata√ß√£o SQL.
"""

import textwrap
from typing import List, Dict, Any


def format_translation_output(result: dict) -> str:
    """
    Formata os resultados da tradu√ß√£o para exibi√ß√£o.
    
    Args:
        result (dict): Resultado da tradu√ß√£o do SQLTranslator
        
    Returns:
        str: String de sa√≠da formatada
    """
    output = []
    output.append("=" * 80)
    output.append(f"üß™ TRADU√á√ÉO #{result['translation_id']}")
    output.append("=" * 80)
    
    output.append(f"\nüìù SQL Original:")
    output.append(f"   {result['original_sql']}")
    
    output.append(f"\nüî• Spark SQL:")
    output.append(f"   {result['spark_sql']}")
    
    if result['translation_available']:
        output.append(f"\nüêç API PySpark DataFrame:")
        pyspark_lines = result['pyspark_code'].split('\n')
        for line in pyspark_lines:
            if line.strip():
                output.append(f"   {line}")
    else:
        output.append(f"\n‚ùå API PySpark DataFrame: N√£o dispon√≠vel (consulta complexa)")
    
    status = 'Sucesso' if result['translation_available'] else 'Parcial (apenas Spark SQL)'
    output.append(f"\n‚úÖ Status da Tradu√ß√£o: {status}")
    
    return '\n'.join(output)


def create_sample_dataframe_code(table_name: str, sample_data: List[Dict[str, Any]]) -> str:
    """
    Gera c√≥digo para criar um DataFrame de exemplo para testes.
    
    Args:
        table_name (str): Nome da tabela/DataFrame
        sample_data (List[Dict[str, Any]]): Dados de exemplo para o DataFrame
        
    Returns:
        str: String de c√≥digo para criar o DataFrame
    """
    code_lines = [
        "from pyspark.sql import SparkSession",
        "from pyspark.sql import functions as F",
        "",
        "# Criar sess√£o Spark",
        'spark = SparkSession.builder.master("local[*]").appName("SQLTranslator").getOrCreate()',
        "",
        f"# Criar dados de exemplo para {table_name}",
        f"{table_name}_data = {sample_data}",
        f"{table_name}_df = spark.createDataFrame({table_name}_data)",
        f'{table_name}_df.createOrReplaceTempView("{table_name}")',
        "",
        f"# Exibir o DataFrame",
        f"{table_name}_df.show()"
    ]
    
    return '\n'.join(code_lines)


def get_test_cases() -> List[Dict[str, str]]:
    """
    Obt√©m casos de teste predefinidos para tradu√ß√£o SQL.
    
    Returns:
        List[Dict[str, str]]: Lista de casos de teste com descri√ß√£o e SQL
    """
    return [
        {
            "description": "SELECT b√°sico - Sele√ß√£o simples de colunas",
            "sql": "SELECT nome, idade FROM usuarios"
        },
        {
            "description": "WHERE com compara√ß√£o num√©rica",
            "sql": "SELECT nome, idade FROM usuarios WHERE idade > 18"
        },
        {
            "description": "WHERE com compara√ß√£o de string",
            "sql": "SELECT nome, departamento FROM funcionarios WHERE departamento = 'TI'"
        },
        {
            "description": "ORDER BY ascendente (padr√£o)",
            "sql": "SELECT nome, salario FROM funcionarios ORDER BY salario"
        },
        {
            "description": "ORDER BY descendente",
            "sql": "SELECT nome, idade FROM usuarios WHERE idade > 18 ORDER BY idade DESC"
        },
        {
            "description": "Combina√ß√£o de WHERE, ORDER BY e LIMIT",
            "sql": "SELECT nome, idade FROM usuarios WHERE idade > 18 ORDER BY idade DESC LIMIT 10"
        },
        {
            "description": "Aliases de coluna",
            "sql": "SELECT nome, idade as idade_usuario FROM usuarios WHERE idade > 18"
        },
        {
            "description": "SELECT todas as colunas",
            "sql": "SELECT * FROM produtos ORDER BY preco"
        },
        {
            "description": "WHERE complexo com condi√ß√£o AND",
            "sql": "SELECT nome, salario FROM funcionarios WHERE salario >= 50000 AND departamento = 'TI'"
        },
        {
            "description": "M√∫ltiplas colunas em ORDER BY",
            "sql": "SELECT nome, idade, salario FROM funcionarios ORDER BY departamento, salario DESC"
        }
    ]


def analyze_translation_results(results: List[dict]) -> dict:
    """
    Analisa os resultados das tradu√ß√µes e fornece estat√≠sticas.
    
    Args:
        results (List[dict]): Lista de resultados de tradu√ß√£o
        
    Returns:
        dict: Estat√≠sticas da an√°lise
    """
    total_translations = len(results)
    successful_translations = sum(1 for r in results if r['translation_available'])
    success_rate = (successful_translations / total_translations) * 100 if total_translations > 0 else 0
    
    return {
        'total_translations': total_translations,
        'successful_translations': successful_translations,
        'success_rate': success_rate,
        'partial_translations': total_translations - successful_translations
    }


def print_analysis_summary(analysis: dict):
    """
    Imprime um resumo formatado da an√°lise.
    
    Args:
        analysis (dict): Resultados da an√°lise de analyze_translation_results
    """
    print("üìä RESUMO DA TRADU√á√ÉO")
    print("=" * 40)
    print(f"Total de Casos de Teste: {analysis['total_translations']}")
    print(f"Tradu√ß√µes PySpark Bem-sucedidas: {analysis['successful_translations']}")
    print(f"Taxa de Sucesso: {analysis['success_rate']:.1f}%")
    print(f"Tradu√ß√µes Parciais (apenas Spark SQL): {analysis['partial_translations']}")
    print()
    
    print("üîß FUNCIONALIDADES SQL SUPORTADAS:")
    features = [
        "SELECT com sele√ß√£o de colunas",
        "Cl√°usulas WHERE com v√°rios operadores",
        "ORDER BY com ASC/DESC",
        "Cl√°usulas LIMIT",
        "Aliases de coluna (AS)",
        "SELECT * (todas as colunas)",
        "Condi√ß√µes complexas com AND/OR"
    ]
    
    for feature in features:
        print(f"‚úÖ {feature}")
    
    print()
    print("üí° RECOMENDA√á√ïES DE USO:")
    recommendations = [
        "Use o c√≥digo PySpark gerado como ponto de partida",
        "Teste com o esquema espec√≠fico do seu DataFrame",
        "Ajuste nomes de colunas e tipos de dados conforme necess√°rio",
        "Considere implica√ß√µes de performance para grandes datasets"
    ]
    
    for rec in recommendations:
        print(f"‚Ä¢ {rec}")
